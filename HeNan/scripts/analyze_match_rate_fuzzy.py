"""
ç‰ˆæƒæ–¹æ•°æ®ä¸æ‰«æç»“æœåŒ¹é…ç‡åˆ†æï¼ˆå¢å¼ºæ¨¡ç³ŠåŒ¹é…ç‰ˆï¼‰

æ”¯æŒçš„åŒ¹é…æ–¹å¼ï¼š
1. ç²¾ç¡®åŒ¹é… - åç§°å®Œå…¨ä¸€è‡´
2. å»ç©ºæ ¼åŒ¹é… - å¿½ç•¥ç©ºæ ¼ååŒ¹é…
3. æ‹¼éŸ³é¦–å­—æ¯åŒ¹é… - ä¸­æ–‡è½¬æ‹¼éŸ³é¦–å­—æ¯ååŒ¹é…
4. åŒ…å«å…³ç³»åŒ¹é… - ä¸€æ–¹åŒ…å«å¦ä¸€æ–¹
5. å»é™¤å¸¸è§åç¼€åŒ¹é… - å»é™¤"ç³»åˆ—"ã€"åŠ¨ç”»"ç­‰åç¼€
"""
import pandas as pd
import os
import re
from pypinyin import lazy_pinyin, Style


def get_pinyin_abbr(text: str) -> str:
    """è·å–ä¸­æ–‡çš„æ‹¼éŸ³é¦–å­—æ¯ç¼©å†™"""
    if not text:
        return ''
    # åªå¤„ç†ä¸­æ–‡å­—ç¬¦
    chinese_chars = re.findall(r'[\u4e00-\u9fff]', text)
    if not chinese_chars:
        return text.lower()
    
    abbr = ''.join(lazy_pinyin(chinese_chars, style=Style.FIRST_LETTER))
    return abbr.lower()


def normalize_name(name: str) -> str:
    """æ ‡å‡†åŒ–åç§°ï¼šå»é™¤ç©ºæ ¼ã€æ‹¬å·ã€ç‰¹æ®Šå­—ç¬¦"""
    if not name:
        return ''
    # å»é™¤ç©ºæ ¼
    name = re.sub(r'\s+', '', name)
    # ç»Ÿä¸€æ‹¬å·
    name = name.replace('ï¼ˆ', '(').replace('ï¼‰', ')')
    # å»é™¤å¸¸è§åç¼€
    name = re.sub(r'(ç³»åˆ—|åŠ¨ç”»|å…¨é›†|åˆé›†|ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+å­£)$', '', name)
    return name.lower()


def extract_core_name(name: str) -> str:
    """æå–æ ¸å¿ƒåç§°ï¼šå»é™¤æ‰€æœ‰éæ ¸å¿ƒå†…å®¹"""
    if not name:
        return ''
    # å»é™¤ç©ºæ ¼ã€æ‹¬å·åŠå…¶å†…å®¹
    name = re.sub(r'\s+', '', name)
    name = re.sub(r'[ï¼ˆ\(][^ï¼‰\)]*[ï¼‰\)]', '', name)
    # å»é™¤å¸¸è§åç¼€
    name = re.sub(r'(ç³»åˆ—|åŠ¨ç”»|å…¨é›†|åˆé›†|ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+å­£|[ç¬¬]?\d+å­£)$', '', name)
    # å»é™¤è‹±æ–‡å‰ç¼€ï¼ˆå¦‚æœåé¢æœ‰ä¸­æ–‡ï¼‰
    if re.search(r'[\u4e00-\u9fff]', name):
        name = re.sub(r'^[a-zA-Z0-9\-_\.]+', '', name)
    return name


def analyze_match_rate_fuzzy():
    base_dir = os.path.dirname(__file__)
    tables_dir = os.path.join(base_dir, '..', 'tables')
    
    # è¯»å–æ•°æ®
    print("ğŸ“‚ æ­£åœ¨è¯»å–æ•°æ®...")
    copyright_df = pd.read_excel(os.path.join(tables_dir, 'ç‰ˆæƒæ–¹æ•°æ®è¡¨.xlsx'))
    scan_df = pd.read_csv(os.path.join(tables_dir, 'scan_result_with_standard_name.csv'))
    
    # è·å–æ‰«æç»“æœä¸­çš„æ ‡å‡†åŒ–å­é›†åç§°
    scan_episode_names = set(scan_df['æ ‡å‡†åŒ–å­é›†åç§°'].dropna().astype(str).str.strip())
    print(f"ğŸ“Š æ‰«æç»“æœå­é›†åç§°æ•°é‡: {len(scan_episode_names)}")
    
    # ä»æ‰«æç»“æœæå–å‰§åï¼ˆå»æ‰"ç¬¬XXé›†"åç¼€ï¼‰
    scan_drama_names = set()
    for name in scan_episode_names:
        match = re.match(r'^(.+?)ç¬¬\d+é›†$', name)
        if match:
            scan_drama_names.add(match.group(1))
    
    # æ„å»ºå¤šç§ç´¢å¼•ç”¨äºæ¨¡ç³ŠåŒ¹é…
    print("ğŸ”§ æ­£åœ¨æ„å»ºåŒ¹é…ç´¢å¼•...")
    
    # ç´¢å¼•1: åŸå§‹åç§°
    scan_names_original = {name: name for name in scan_drama_names}
    
    # ç´¢å¼•2: æ ‡å‡†åŒ–åç§°ï¼ˆå»ç©ºæ ¼ç­‰ï¼‰
    scan_names_normalized = {}
    for name in scan_drama_names:
        normalized = normalize_name(name)
        if normalized:
            scan_names_normalized[normalized] = name
    
    # ç´¢å¼•3: æ‹¼éŸ³é¦–å­—æ¯
    scan_names_pinyin = {}
    for name in scan_drama_names:
        pinyin = get_pinyin_abbr(name)
        if pinyin and len(pinyin) >= 3:  # è‡³å°‘3ä¸ªå­—ç¬¦
            if pinyin not in scan_names_pinyin:
                scan_names_pinyin[pinyin] = []
            scan_names_pinyin[pinyin].append(name)
    
    # ç´¢å¼•4: æ ¸å¿ƒåç§°
    scan_names_core = {}
    for name in scan_drama_names:
        core = extract_core_name(name)
        if core and len(core) >= 2:
            if core not in scan_names_core:
                scan_names_core[core] = []
            scan_names_core[core].append(name)
    
    print(f"  - åŸå§‹åç§°ç´¢å¼•: {len(scan_names_original)}")
    print(f"  - æ ‡å‡†åŒ–åç§°ç´¢å¼•: {len(scan_names_normalized)}")
    print(f"  - æ‹¼éŸ³é¦–å­—æ¯ç´¢å¼•: {len(scan_names_pinyin)}")
    print(f"  - æ ¸å¿ƒåç§°ç´¢å¼•: {len(scan_names_core)}")
    
    # è·å–ç‰ˆæƒæ–¹æ•°æ®
    media_col = [c for c in copyright_df.columns if 'ä»‹è´¨åç§°' in str(c)][0]
    episode_col = [c for c in copyright_df.columns if 'é›†æ•°' in str(c)][0]
    
    # å»é‡è·å–ä»‹è´¨åç§°
    seen_media = set()
    media_list = []
    for _, row in copyright_df.iterrows():
        name = str(row[media_col]).strip() if pd.notna(row[media_col]) else ''
        if name and name != 'nan' and name not in seen_media:
            seen_media.add(name)
            ep_str = str(row[episode_col]).strip() if pd.notna(row[episode_col]) else '0'
            ep_match = re.search(r'\d+', ep_str)
            episode_count = int(ep_match.group()) if ep_match else 0
            media_list.append({'name': name, 'episode_count': episode_count})
    
    print(f"ğŸ“Š ç‰ˆæƒæ–¹ä»‹è´¨åç§°æ•°é‡: {len(media_list)}")
    
    # å¼€å§‹åŒ¹é…
    print("\nğŸ” å¼€å§‹æ¨¡ç³ŠåŒ¹é…åˆ†æ...")
    
    match_results = []
    total_episodes = 0
    matched_episodes = 0
    
    for item in media_list:
        media_name = item['name']
        episode_count = item['episode_count']
        total_episodes += episode_count
        
        # å°è¯•å¤šç§åŒ¹é…æ–¹å¼
        matched_scan_name = None
        match_type = 'æœªåŒ¹é…'
        
        # 1. ç²¾ç¡®åŒ¹é…
        if media_name in scan_names_original:
            matched_scan_name = media_name
            match_type = 'ç²¾ç¡®åŒ¹é…'
        
        # 2. æ ‡å‡†åŒ–åç§°åŒ¹é…
        if not matched_scan_name:
            normalized = normalize_name(media_name)
            if normalized in scan_names_normalized:
                matched_scan_name = scan_names_normalized[normalized]
                match_type = 'æ ‡å‡†åŒ–åŒ¹é…'
        
        # 3. æ ¸å¿ƒåç§°åŒ¹é…
        if not matched_scan_name:
            core = extract_core_name(media_name)
            if core and core in scan_names_core:
                # å¦‚æœæœ‰å¤šä¸ªåŒ¹é…ï¼Œé€‰ç¬¬ä¸€ä¸ª
                matched_scan_name = scan_names_core[core][0]
                match_type = 'æ ¸å¿ƒåç§°åŒ¹é…'
        
        # 4. æ‹¼éŸ³é¦–å­—æ¯åŒ¹é…
        if not matched_scan_name:
            pinyin = get_pinyin_abbr(media_name)
            if pinyin and len(pinyin) >= 4 and pinyin in scan_names_pinyin:
                # æ‹¼éŸ³åŒ¹é…éœ€è¦é¢å¤–éªŒè¯é•¿åº¦æ¥è¿‘
                candidates = scan_names_pinyin[pinyin]
                for candidate in candidates:
                    # éªŒè¯é•¿åº¦ç›¸è¿‘ï¼ˆå…è®¸å·®3ä¸ªå­—ç¬¦ï¼‰
                    if abs(len(media_name) - len(candidate)) <= 3:
                        matched_scan_name = candidate
                        match_type = 'æ‹¼éŸ³é¦–å­—æ¯åŒ¹é…'
                        break
        
        # 5. åŒ…å«å…³ç³»åŒ¹é…ï¼ˆè¾ƒå®½æ¾ï¼‰
        if not matched_scan_name:
            media_core = extract_core_name(media_name)
            if media_core and len(media_core) >= 4:
                for scan_name in scan_drama_names:
                    scan_core = extract_core_name(scan_name)
                    if scan_core and len(scan_core) >= 4:
                        if media_core in scan_core or scan_core in media_core:
                            matched_scan_name = scan_name
                            match_type = 'åŒ…å«å…³ç³»åŒ¹é…'
                            break
        
        # ç»Ÿè®¡å­é›†åŒ¹é…
        ep_matched = 0
        if matched_scan_name and episode_count > 0:
            for ep in range(1, episode_count + 1):
                ep_name = f"{matched_scan_name}ç¬¬{ep:02d}é›†"
                if ep_name in scan_episode_names:
                    ep_matched += 1
        
        matched_episodes += ep_matched
        
        match_results.append({
            'ä»‹è´¨åç§°': media_name,
            'æ€»é›†æ•°': episode_count,
            'åŒ¹é…åˆ°çš„æ‰«æåç§°': matched_scan_name or '',
            'åŒ¹é…ç±»å‹': match_type,
            'åŒ¹é…å­é›†æ•°': ep_matched,
            'å­é›†åŒ¹é…ç‡': f"{ep_matched/episode_count*100:.1f}%" if episode_count > 0 else '0%'
        })
    
    # ç»Ÿè®¡
    match_type_counts = {}
    for r in match_results:
        t = r['åŒ¹é…ç±»å‹']
        match_type_counts[t] = match_type_counts.get(t, 0) + 1
    
    total_dramas = len(match_results)
    matched_dramas = total_dramas - match_type_counts.get('æœªåŒ¹é…', 0)
    
    print("\n" + "="*70)
    print("ğŸ“Š æ¨¡ç³ŠåŒ¹é…åˆ†æç»“æœ")
    print("="*70)
    
    print(f"\nã€å‰§é›†ç»´åº¦ã€‘")
    print(f"  æ€»å‰§é›†æ•°:           {total_dramas}")
    for match_type, count in sorted(match_type_counts.items(), key=lambda x: -x[1]):
        print(f"  {match_type}:       {count} ({count/total_dramas*100:.1f}%)")
    print(f"  ---------------")
    print(f"  åŒ¹é…æˆåŠŸæ€»è®¡:       {matched_dramas} ({matched_dramas/total_dramas*100:.1f}%)")
    
    print(f"\nã€å­é›†ç»´åº¦ã€‘")
    print(f"  æ€»å­é›†æ•°:           {total_episodes}")
    print(f"  åŒ¹é…æˆåŠŸ:           {matched_episodes} ({matched_episodes/total_episodes*100:.1f}%)")
    print(f"  æœªåŒ¹é…:             {total_episodes - matched_episodes} ({(total_episodes - matched_episodes)/total_episodes*100:.1f}%)")
    print("="*70)
    
    # å¯¼å‡ºç»“æœ
    output_path = os.path.join(tables_dir, 'æ¨¡ç³ŠåŒ¹é…åˆ†æç»“æœ.xlsx')
    
    with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
        # Sheet 1: æ‰€æœ‰åŒ¹é…ç»“æœ
        results_df = pd.DataFrame(match_results)
        results_df = results_df.sort_values(by=['åŒ¹é…ç±»å‹', 'åŒ¹é…å­é›†æ•°'], ascending=[True, False])
        results_df.to_excel(writer, sheet_name='åŒ¹é…è¯¦æƒ…', index=False)
        
        # Sheet 2: æœªåŒ¹é…
        unmatched = [r for r in match_results if r['åŒ¹é…ç±»å‹'] == 'æœªåŒ¹é…']
        pd.DataFrame(unmatched).to_excel(writer, sheet_name='æœªåŒ¹é…', index=False)
        
        # Sheet 3: æ‹¼éŸ³åŒ¹é…ç¤ºä¾‹
        pinyin_matched = [r for r in match_results if r['åŒ¹é…ç±»å‹'] == 'æ‹¼éŸ³é¦–å­—æ¯åŒ¹é…']
        pd.DataFrame(pinyin_matched).to_excel(writer, sheet_name='æ‹¼éŸ³åŒ¹é…', index=False)
        
        # Sheet 4: ç»Ÿè®¡æ‘˜è¦
        summary = {
            'åŒ¹é…ç±»å‹': list(match_type_counts.keys()) + ['åŒ¹é…æˆåŠŸæ€»è®¡', 'æ€»å‰§é›†æ•°', 'å­é›†åŒ¹é…æ•°', 'å­é›†æ€»æ•°'],
            'æ•°é‡': list(match_type_counts.values()) + [matched_dramas, total_dramas, matched_episodes, total_episodes]
        }
        pd.DataFrame(summary).to_excel(writer, sheet_name='ç»Ÿè®¡æ‘˜è¦', index=False)
    
    print(f"\nğŸ“ å·²ç”Ÿæˆåˆ†ææ–‡ä»¶: {output_path}")


if __name__ == '__main__':
    analyze_match_rate_fuzzy()
